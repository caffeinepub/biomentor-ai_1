{
  "kind": "implementation_plan",
  "version": "1.0",
  "title": "Fix broken Live Voice Chat feature",
  "requirements": [
    {
      "id": "REQ-12",
      "summary": "Audit and fix the Live Voice Chat feature to ensure proper rendering, speech recognition, AI response handling, text-to-speech playback, and real-time transcript updates without errors",
      "acceptanceCriteria": [
        "The Voice Chat tab is visible and clickable on the AI Tutor page without any runtime errors.",
        "Clicking the microphone button activates speech recognition and the status indicator shows 'Listening…'.",
        "After the student finishes speaking, the status changes to 'Thinking…' and the recognized text is sent to the bioAI logic.",
        "The AI response is spoken aloud via speechSynthesis and the status indicator shows 'Speaking…'.",
        "The transcript panel shows each student and AI turn in real time.",
        "If the student speaks while the AI is talking, speechSynthesis stops immediately and recognition restarts.",
        "The waveform or pulsing animation is visible during both listening and speaking states.",
        "No unhandled JavaScript exceptions are thrown during a full voice interaction cycle.",
        "The feature degrades gracefully in browsers that do not support the Web Speech API, showing an informative message."
      ],
      "file_operations": [
        {
          "path": "frontend/src/hooks/useVoiceChat.ts",
          "operation": "modify",
          "description": "Fix the useVoiceChat hook to properly manage Web Speech API lifecycle: ensure SpeechRecognition starts/stops correctly, handle state transitions (idle → listening → thinking → speaking → idle) without race conditions, implement proper cleanup of recognition and synthesis instances, add error boundary for browsers lacking Web Speech API support, and ensure speechSynthesis.cancel() is called before starting new recognition when the user interrupts the AI."
        },
        {
          "path": "frontend/src/components/VoiceChatInterface.tsx",
          "operation": "modify",
          "description": "Fix the VoiceChatInterface component to properly render the microphone button, status badge, waveform animation, and transcript panel. Ensure the microphone button correctly toggles listening state via the useVoiceChat hook, the status badge displays the current state ('Listening…', 'Thinking…', 'Speaking…'), the waveform or pulsing animation is visible during listening and speaking states, the transcript scroll area auto-scrolls to the latest turn, and a fallback message is shown if the Web Speech API is unavailable."
        },
        {
          "path": "frontend/src/pages/AITutor.tsx",
          "operation": "modify",
          "description": "Fix the Voice Chat tab rendering in AITutor.tsx to ensure the tab is properly wired into the tabs component without runtime errors. Verify the VoiceChatInterface component is correctly imported and rendered when the Voice Chat tab is active. Ensure proper prop passing between AITutor and VoiceChatInterface, including any callbacks for saving conversation turns to the backend via addConversationTurn."
        },
        {
          "path": "frontend/src/lib/bioAI.ts",
          "operation": "modify",
          "description": "Review and fix the bioAI.ts client-side AI response logic to ensure it correctly handles voice chat queries. Verify the function returns appropriate biology tutoring responses based on keyword matching without throwing exceptions. Ensure the response format is compatible with text-to-speech synthesis (avoiding special characters or markup that might cause speechSynthesis issues)."
        }
      ]
    }
  ]
}