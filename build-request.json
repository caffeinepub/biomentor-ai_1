{
  "kind": "build_request",
  "title": "Fix broken Live Voice Chat feature",
  "projectName": "BioMentor AI",
  "priority": "high",
  "requirements": [
    {
      "id": "REQ-12",
      "text": "Audit and fix the Live Voice Chat feature in frontend/src/pages/AITutor.tsx and frontend/src/components/VoiceChatInterface.tsx. Ensure the Voice Chat tab renders correctly, the microphone button starts/stops speech recognition via the Web Speech API (SpeechRecognition), the recognized speech is passed to the bioAI client-side logic in frontend/src/lib/bioAI.ts, the AI response is read aloud via speechSynthesis, and the transcript panel updates in real time. Verify the useVoiceChat hook (frontend/src/hooks/useVoiceChat.ts) correctly transitions between 'Listening', 'Thinking', and 'Speaking' states without errors.",
      "target": "frontend",
      "source": {
        "messageIds": [
          "msg-4"
        ],
        "quotes": [
          "its not working"
        ]
      },
      "acceptanceCriteria": [
        "The Voice Chat tab is visible and clickable on the AI Tutor page without any runtime errors.",
        "Clicking the microphone button activates speech recognition and the status indicator shows 'Listening…'.",
        "After the student finishes speaking, the status changes to 'Thinking…' and the recognized text is sent to the bioAI logic.",
        "The AI response is spoken aloud via speechSynthesis and the status indicator shows 'Speaking…'.",
        "The transcript panel shows each student and AI turn in real time.",
        "If the student speaks while the AI is talking, speechSynthesis stops immediately and recognition restarts.",
        "The waveform or pulsing animation is visible during both listening and speaking states.",
        "No unhandled JavaScript exceptions are thrown during a full voice interaction cycle.",
        "The feature degrades gracefully in browsers that do not support the Web Speech API, showing an informative message."
      ]
    }
  ],
  "constraints": [
    "Do not modify any files under frontend/src/hooks/useInternetIdentity.ts, frontend/src/hooks/useActor.ts, frontend/src/main.tsx, or frontend/src/components/ui.",
    "All AI response logic must remain client-side in frontend/src/lib/bioAI.ts — no new backend calls for voice chat responses.",
    "Do not alter the backend schema or Motoko actor."
  ],
  "nonGoals": [
    "Adding new backend endpoints for voice chat.",
    "Replacing the Web Speech API with a third-party speech service.",
    "Changes to any feature module other than the Voice Chat tab on the AI Tutor page."
  ],
  "imageRequirements": {
    "required": [],
    "edits": []
  }
}